---
layout: default
title: L2&#58; Shape-Based Classification
parent: Classification
grand_parent: Signals
has_toc: false # (on by default)
comments: false
---

# {{ page.title | replace_first:'L','Lesson '}}
{: .no_toc }

---

This [Notebook](gesturerec/shapebased/index.html) introduces a shape-based (or template-based) approach to gesture recognition and provides the scaffolding for the A3 assignment.

You can view the Notebook in [html here](gesturerec/shapebased/index.html) but we also **strongly** recommend working with our Notebooks locally by performing a git clone on `https://github.com/makeabilitylab/signals.git` and running the [Jupyter Notebook](https://github.com/makeabilitylab/signals/blob/master/Projects/GestureRecognizer/GestureRecognizer-ShapeBased.ipynb) on your system (see [installation notes](jupyter-notebook.md)).

## Next Lesson

In the [next lesson](gesturerec-feature-based.md), you'll learn how to build a feature-based gesture recognizer for 3D accelerometer signals using a Support Vector Machine (SVM) and other classification models.

<span class="fs-6">
[Previous: Heuristic-Based Step Tracker](step-tracker.md){: .btn .btn-outline }
[Next: Feature-Based Gesture Recognition](gesturerec-feature-based.md){: .btn .btn-outline }
</span>